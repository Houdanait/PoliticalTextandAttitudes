{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the non_pprm dataset\n",
    "\n",
    "This makes a sample of words that have not been identified as pragmatic markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Load the transcripts and phrases from JSON files\n",
    "with open('data/news_dialogue_large_sample.json', 'r') as file:\n",
    "    transcripts = json.load(file)\n",
    "\n",
    "with open('data/pprms/authority_markers.json', 'r') as file:\n",
    "    search_terms = json.load(file)\n",
    "\n",
    "with open('data/pprms/hedging_markers.json', 'r') as file:\n",
    "    search_terms +=json.load(file)\n",
    "\n",
    "def filter_non_matching_utterances(transcripts, terms):\n",
    "    # Function to filter utterances that do not match any of the terms\n",
    "    results = []\n",
    "    for transcript in transcripts:\n",
    "        previous_utterance = None\n",
    "        for current_index, utterance in enumerate(transcript['utt']):\n",
    "            matched = False  # Track if any term matches\n",
    "            # Check each term separately\n",
    "            for term in terms:\n",
    "                if re.search(rf\"\\b{re.escape(term)}\\b\", utterance, re.IGNORECASE):\n",
    "                    matched = True\n",
    "                    break  # Break the loop if any term matches\n",
    "            # If no terms matched, collect the utterance\n",
    "            if not matched:\n",
    "                result = {\n",
    "                    \"transcript_id\": transcript['id'],\n",
    "                    \"previous_statement\": previous_utterance if previous_utterance else \"None\",\n",
    "                    \"statement\": utterance\n",
    "                }\n",
    "                results.append(result)\n",
    "            # Update the previous utterance\n",
    "            previous_utterance = utterance\n",
    "    return results\n",
    "\n",
    "# Get the filtered list of non-matching utterances\n",
    "non_matching_utterances = filter_non_matching_utterances(transcripts, search_terms)\n",
    "\n",
    "# Sample 100 entries randomly from the results if there are more than 100\n",
    "sampled_non_matching_utterances = random.sample(non_matching_utterances, min(100, len(non_matching_utterances)))\n",
    "\n",
    "# Save the non-matching utterances to a JSON file\n",
    "output_file_path = 'data/non_matching_utterances.json'\n",
    "with open(output_file_path, 'w') as file:\n",
    "    json.dump(non_matching_utterances, file, indent=4)\n",
    "\n",
    "output_file_path = 'data/non_matching_utterances_sample.json'\n",
    "with open(output_file_path, 'w') as file:\n",
    "    json.dump(sampled_non_matching_utterances, file, indent=4)\n",
    "\n",
    "# Optionally, you can print the JSON to check the output\n",
    "# print(json.dumps(sampled_non_matching_utterances, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 100 entries randomly from the results if there are more than 100\n",
    "sampled_non_matching_utterances = random.sample(non_matching_utterances, min(100, len(non_matching_utterances)))\n",
    "\n",
    "# Save the non-matching utterances to a JSON file\n",
    "output_file_path = 'data/non_matching_utterances.json'\n",
    "with open(output_file_path, 'w') as file:\n",
    "    json.dump(non_matching_utterances, file, indent=4)\n",
    "\n",
    "output_file_path = 'data/non_matching_utterances_sample.json'\n",
    "with open(output_file_path, 'w') as file:\n",
    "    json.dump(sampled_non_matching_utterances, file, indent=4)\n",
    "\n",
    "# print(\"Filtered Utterances:\", len(sampled_non_matching_utterances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Utterances: 49761\n",
      "Filtered Utterances: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"Filtered Utterances:\", len(non_matching_utterances))\n",
    "print(\"Filtered Utterances:\", len(sampled_non_matching_utterances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70423\n",
      "400\n",
      "88\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load your initial JSON data and the graded dataset\n",
    "with open('data/filtered_utterances.json', 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Define the list of markers\n",
    "with open('data/short_prm_list.json', 'r') as merge_file:\n",
    "    markers = json.load(merge_file)\n",
    "\n",
    "with open('data/filtered_utterances_samples_MW_HNEB_MERGE.json', 'r') as merge_file:\n",
    "    graded_data = json.load(merge_file)\n",
    "\n",
    "with open('data/new_filtered_utterances_to_grade/filtered_data_MW_part_1.json', 'r') as merge_file2:\n",
    "    graded_data2 = json.load(merge_file2)\n",
    "\n",
    "with open('data/new_filtered_utterances_to_grade/filtered_data_MW_part_2.json', 'r') as merge_file3:\n",
    "    graded_data3 = json.load(merge_file3)\n",
    "\n",
    "with open('data/new_filtered_utterances_to_grade/filtered_data_MW_part_3.json', 'r') as merge_file3:\n",
    "    graded_data4 = json.load(merge_file3)\n",
    "\n",
    "full_grade_data = graded_data+graded_data2+graded_data3+graded_data4\n",
    "\n",
    "# Extract statements from graded data for exclusion\n",
    "# graded_statements = {item['statement'] for item in full_grade_data}\n",
    "graded_statements = {item['transcript_id'] + \" - \" + item['previous_statement'] for item in full_grade_data}\n",
    "\n",
    "print(len(json_data))\n",
    "print(len(graded_statements))\n",
    "print(len(markers))\n",
    "# i=0\n",
    "# for k in graded_statements:\n",
    "#     if i == 2:\n",
    "#         break\n",
    "#     else:\n",
    "#         print(k)\n",
    "#         i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 10000 samples: {'transcript_id': 'CNN-21637', 'matched_terms': {'of course': 'ungraded', 'sure': 'ungraded', 'clear': 'ungraded', 'obviously': 'ungraded'}, 'previous_statement': 'And, Eileen, as they do go about considering that, are they considering more than legal options? Are they checking in with Democratic supporters and leaders within the party to see how much support really there would be out there for continued fight?', 'statement': \"Right now, the only information I have is that they've been talking amongst themselves with aides. I'm <SURE> they're getting some input <OF COURSE> from Democrats. They've been told from the Democrats that -- from major Democratic Party officials that they will support anything the vice president does. <OBVIOUSLY>, he's under increasing public and political pressure to end this thing, and he's already said that if the decision was <CLEAR> to him, after all of this, these legal wrangles and the court decision was clear to him, that the election was over, that he would concede. So right now, it's basically just making sure that that is the decision -- Daryn.\"}\n",
      "Filtered 20000 samples: {'transcript_id': 'NPR-38208', 'matched_terms': {'think': 'ungraded', 'may': 'ungraded'}, 'previous_statement': \"But there's a problem with this analysis, says conservative intellectual Norman Podhoretz.\", 'statement': \"However inconvenient it <MAY> be and difficult to explain, I still <THINK> that the truth is that it's World War IV.\"}\n",
      "Filtered 30000 samples: {'transcript_id': 'CNN-123036', 'matched_terms': {'think': 'ungraded'}, 'previous_statement': 'Well, in fact, there have been about 15 different studies that have been done over the years. Although the results were similar, critics were quick to point out that there were biases such as small numbers of participants, not controlling for age, smoking, and even morning sickness, which causes some women to avoid caffeine altogether. Researchers in this study looked at women early in their pregnancies who never changed their drinking patterns. And it was a large study, too, over a thousand women. And the results were pretty startling. Those who consumed 200 milligrams of caffeine per day had twice the miscarriage risk of women who consumed no caffeine at all. Now, current recommendations from groups such as the March of Dimes warn women not to exceed 300 milligrams a day. So this may actually force a change in recommendations the next time women go to their doctors.', 'statement': 'Indeed. So why do doctors <THINK> that caffeine can cause these miscarriages?'}\n",
      "Filtered 40000 samples: {'transcript_id': 'CNN-322134', 'matched_terms': {'know': 'ungraded', 'might': 'ungraded'}, 'previous_statement': 'All right. Phil, thanks.', 'statement': \"Look, there <MIGHT> be some moderate senators that we don't <KNOW> that they're no's. So if you put this bill on the floor you might have some of those senators who have to come out for their constituents and vote no on a bill and put them in a tough position for 2018.\"}\n",
      "Filtered 50000 samples: {'transcript_id': 'CNN-283377', 'matched_terms': {'think': 'ungraded', 'hope': 'ungraded'}, 'previous_statement': 'So, Mr. Speaker, you have said throughout this process that you will support the Republican presidential nominee. Now you have a presumptive nominee, Donald Trump. Will you support him?', 'statement': \"Well, to be perfectly candid with you, Jake, I'm just not ready to do that at this point. I'm not there right now. And I <HOPE> to, though, and I want to but I <THINK> what is required is that we unify this party and I think the bulk of the burden on unifying the party will have to come from our presumptive nominee.\"}\n",
      "Filtered 60000 samples: {'transcript_id': 'CNN-350412', 'matched_terms': {'absolutely': 'ungraded'}, 'previous_statement': \"I was told by the governor, Jerry Brown, that it's now becoming very, very difficult and they're still lagging behind. The government has to help.\", 'statement': \"But in any case, the problem is that the same is happening everywhere, even with countries of governments that have signed the Paris Agreement has remain committed to it. Climate change is running faster than we are. We are not meeting the commitments made in Paris. And it's <ABSOLUTELY> essential to increase the ambition because all the forecasts that were made are proven to be, I would say, conservative when we look at the reality. And the last three years were -- this\"}\n",
      "Graded Statement Skipped 291:  Well, number one, the -- under \"don't ask, don't tell,\" it was developed six years ago and it sat in the Pentagon for six years. The anti-harassment training wasn't even passed down into the armed forces until three months after my son's death. If that training had started six years ago, <PERHAPS> my son would be alive today; perhaps the climate of violence and harassment wouldn't exist that's in the military today.\n",
      "Graded Statement Skipped 292:  And then there's the generals. When Vice President Pence calls for those who've carried out the atrocities against the Rohingya to be held accountable, he's talking about the military. But they're still very powerful back home. And Suu Kyi can't stop them, can't discipline them even if she wanted to. And that's a big if. And all of this means the Rohingya, Steve, have no good options and <PROBABLY> won't for a very long time.\n",
      "Graded Statement Skipped 293:  Well, thank you. We`ll take every viewer we can get, Lisa. Appreciate you being here. And I <KNOW>, I`m <SURE> you`ve been offered other reality shows over the years. I`m sure people are always knocking on your door to do this project, that project. This is the first one you`ve done. Fifteen million people watched you get booted off on Friday night.\n",
      "Graded Statement Skipped 294:  Officials also say the couple had money problems and <MAY> have been in debt. They'd recently moved to the area from Florida.\n",
      "Graded Statement Skipped 295:  We've got a number of new nuggets as it were, not least this New York Times obtaining a twenty page letter that his lawyers wrote back in January, and we have to be <CLEAR> about, this is back in January to Special Counsel Robert Mueller claiming the President cannot legally obstruct justice because effectively is in charge of federal investigations. What are we to make of all of this? I mean, we are looming towards five hundred days in office for the President and not many less than that for Mueller's investigation. We've got midterms coming up in November. Just walk us through where we are at, at this point.\n",
      "Graded Statement Skipped 296:  Well, look, the point isn't to look back and cast blame. We'll leave that to the politicians. But General, you <KNOW>, the giveaway for me there was the way I pronounced laboratory. It was a British intelligence source who said to me that this place is a big concern now and no joke, because you have all of the -- it <MAY> become a welcoming ground for any extremism that wants to get involved, that the Houthis, you know, just based on what they're about. As long as they're in control, they don't care who is there, as long as it's disruptive. And what <COULD> that mean? Having a place where, whether it's ISIS or al Qaeda or whoever you want to put down as a name can come there and share information and grow.\n",
      "Graded Statement Skipped 297:  ... didn't even do a moratorium. He just did a study or a look at a moratorium. So, again, something's wrong. Either the president doesn't <KNOW> what he's talking about -- <CLEARLY>, his aides don't know what he is talking about -- and -- or something's very wrong here about meeting the needs of the American people at this time.\n",
      "Graded Statement Skipped 298:  First of all, you have to remember that the overwhelming majority of Republican senators have not endorsed anyone. You've got a handful who have endorsed. I'm the first one who has endorsed Ted Cruz. I'm <CONFIDENT> that I will not be the last. I'm <SURE> others will follow.\n",
      "Graded Statement Skipped 299:  This is from the perspective of King's camera where not long after, Lane asks if Floyd <SHOULD> be moved.\n",
      "Graded Statement Skipped 300:  Well, they're looking at it in much the same way they look at the general public, that they need to talk about this in terms of civil rights and in terms of giving gay couples the same benefits that other couples enjoy. So, they look at it in the same way. This is not, I <MUST> say, an issue that comes up a lot on the campaign trail. Again, as John explained, it doesn't have the power it used to have in <SORT OF> getting people to say, listen, you <KNOW>, the Democrats are all about gay issues. One of the things that the Democrats do have to be careful of, though, is to make <SURE> that they don't look as though as some of them have accused the Democrats of doing -- the Republicans have accused them of them -- of saying: listen, there are so many more important things, why are they focusing on this, it's pandering. So, if begin to look like you're pandering, no matter who you're pandering to, that's a political problem.\n",
      "Graded Statement Skipped 301:  Ana, we <DEFINITELY> are hearing some tough words from the regime of the president of Bashar al-Assad and also it's Russian and Iranian backers essentially saying if the U.S. pulls something like this again, there will be real consequences. Now, this was always the argument that the Obama administration had given for not intervening more forcefully or militarily inside Syria. That <PERHAPS> in doing so it <COULD> precipitate or escalate an actual clash between U.S. forces and Russian forces <POTENTIALLY> leading to some <KIND OF> a global conflict or a World War III. That would be a worst case scenario. But at this stage, we still don't really <KNOW> exactly what Trump's policy in Syria is going to look like. We have seen some glimpses of it today hearing from U.N. ambassador Nikki Haley who said Assad is definitely one of our priorities in the sense that he <SHOULD> go. Hearing frankly different message from secretary state Tillerson that our priority fundamentally is the fight against ISIS. And <OF COURSE> the concern from some is that it's difficult to engage in that fight against ISIS without some fundamental level of cooperation with the Russians. A very complex situation in Syria. A lot of very nuanced issues to be taken into account. And these are exactly the sorts of issues that secretary of state Rex Tillerson and his Russian counterpart Sergey Lavrov will be hashing out later this week -- Ana.\n",
      "Graded Statement Skipped 302:  But, you <KNOW>, he <SHOULD> know these types of things, the Flores settlement, that doesn't mean the judge, Flores.\n",
      "Graded Statement Skipped 303:  Now, we come back to the same question, though, about how you <KNOW> that they were illegal if you didn't use a method of probable cause that we are not supposed to use in this country? There are 25 years of laws and standards used by police departments where they're real careful about probable cause so we don't create a Gestapo environment in this country.\n",
      "Graded Statement Skipped 304:  The Vines that you've posted show some incredible sights and sounds, rockets, shaking buildings, ambulances in the night. What do you want people to <KNOW> about life inside Gaza?\n",
      "Graded Statement Skipped 305:  Are you a good note taker? You <KNOW>, when you're sitting in class listening to your teacher, do you take good notes? If so, that attention to detail <COULD> help you later in life. Take managing your money, for example. Writing checks is a part of everyday life and requires careful record keeping. If you don't keep good records, you could bounce a check, and that means big penalty fees from your bank. Bouncing a check means you wrote a check to someone without having the money in your account to back it up -- not a good way to make friends. Unfortunately, there are lots of people who aren't managing their money well. In <FACT>, banks earn more than $6 billion a year in profits from bounced check charges. Steve Young has that.\n",
      "Graded Statement Skipped 306:  Michel Chamberland lives in the Beacon Hill neighborhood of Fort McMurray, an area now more than three-quarters destroyed. He works the overnight shift at an oil company. So he was asleep Tuesday afternoon when he got a call from a friend to get out. He grabbed a few things and left in his truck, filming from the front and back cameras. He let his office <KNOW> he wouldn't be in that night. At several points, you can see embers from the fire had landed across the street, lighting new fires near the houses. As he drove on, embers started falling on his truck and on the vehicles of those <AROUND> him. He said he <COULD> <FEEL> the pressure to try to get out of there and the <VIEW> looking backward was even more hellish. Finally, he sees the smoke <CLEARING> ahead of him and calls a friend.\n",
      "Graded Statement Skipped 307:  All right, stand by. Stick with it, Joe. We need to <KNOW>. Joe Carter from HLN Sports. Appreciate it. In the next half hour, the NBA three-week-old lockout has some stars looking toward Europe to <POSSIBLY> play during the stoppage. That list <REPORTEDLY> includes Lakers star Kobe Bryant. We'll talk about the economics and likelihood straight ahead right here in the CNN NEWSROOM. We know it is hot, 55, 55 different record highs recorded yesterday. Who <KNOWS> what will be set today. The heat is now causing the power authority in Detroit to start rolling blackouts in parts of the city. The Great Lakes, Ohio Valley and the northeast <MAY> see triple- digit temperatures as the day goes on, a pretty rare occurrence. Rob Marciano in the CNN Severe Weather Center. As I said to you last hour, dangerous. We say it a lot, but this really is.\n",
      "Graded Statement Skipped 308:  Oh, yes, <ABSOLUTELY>. Europe achieved it, and a number of other countries did. But it only applied to industrial countries, 40 of them. This is 192, it's a lot more. Canada was onboard to begin with, but I did visit Canada in -- I <THINK> it was in 2006, and met Rosa Ambrose, I think she was the environment secretary. She didn't last 12 months. But she told me <QUITE> <CLEARLY> that the -- this government, the Harper government, were not going to observe Kyoto. So, what they did, instead of meeting the 7 percent goal, which other countries were doing, they burst ahead, got a 17 percent plus, and took no notice, and intended anyway to leave Kyoto. And for them to talk about, now, \"I <BELIEVE> in the new agreement,\" can you trust a government that couldn't even actually achieve what it was supposed to do under Kyoto one, now promising to do something by 2015? Well, it'd have to be a remarkable transformation from what they are at the moment.\n",
      "Graded Statement Skipped 309:  You <KNOW>, there's no <DOUBT> in my mind that Laura will never be used again. That name will be retired. It was the most intense storm to make landfall in Louisiana in 164 years. It has since this weekend, it's now a tropical depression, it is moving to the east and as it moves to the east it will continue to weaken. And on this journey towards the mid-Atlantic, it's going to put much of this region under the risk for some severe weather and rainfall. I mean, down here across the southwest, from central Alabama up to southern Kentucky, you <COULD> see some very strong winds today. And also some isolated tornados. The highest risk for severe weather today though is with the separate system pushing down across the Midwest. Level 3 risk for portions of Iowa going into Illinois. This is something they don't need to see because a couple of weeks ago they were dealing with that derecho.\n",
      "Graded Statement Skipped 310:  I <THINK> we can tell by your excitement you <KNOW> what this is.\n",
      "Graded Statement Skipped 311:  Well, I <THINK> that there's a lot of unanswered questions --\n",
      "Graded Statement Skipped 312:  I <THINK> from Israel's perspective, once the Twin Towers were attacked, once this attack emanated from Middle East it was a question of time before the United States came into the Middle East to deal with the threat against the United States. Any threat against the United States as the leader of the free world is an attack also against the allies of the United States and as such I think from Israel's point of <VIEW>, the decisiveness of the American decision to go ahead has been a very important one and a very important plus in our estimation.\n",
      "sample_statement correctly skipped added: CNN-412394 - It's important say over and over and over and over and over again on this day, we wish the president well and we wish him a speedy recovery but it is just a fact, it is just a fact that his behavior, the way he has conducted himself in recent days and weeks is directly contrary to the advice of his own experts.\n",
      "Graded Statement Skipped 313:  We're all praying for the president, praying for the First Lady and any of other folks that <MAY> end up testing positive as well but it is also true that the president in many ways with his behavior and his rhetoric opened the door to the White House to this virus and remember the White House is both a place of business, it's a workplace and it's also a residence, right? So if you <THINK> about those people who come to work every day, they were left very vulnerable because it was a president who didn't really like the look of masks. He <THOUGHT> mask were essentially ugly and didn't want folks <AROUND> him wearing them and so that is the <KIND OF> environment that was created. And listen, a virus is always looking for host and so this is what ends up happening. Again thoughts and prayers go out to everyone who <MIGHT> end up being affected by this and the folks who already are. But the president <OBVIOUSLY> did himself no favors, he did his family members no favors and the people who work around him. He's the boss of those folks and he set a real I think leadership pattern and they followed because that is what they thought that this president wanted and the same with his supporters, the same with his family members who went to that a debate and were asked to put on masks and <APPARENTLY> refused to put on masks because that is what those <SORT OF> Trump way was in terms of wearing masks. <MAYBE> it'll change, maybe this will be a wakeup call off for this White House and for this administration. We <CERTAINLY> <HOPE> so because you <KNOW> Americans all over you know since March have been changing their ways, their way of life in terms of mask, I've got a mask right here and when I go on to the hallway in CNN, I'm getting my temperature checked and the idea that this White House was so well sort of lackadaisical in their approach to folks who were coming to work every day. They essentially <SEEM> to think that the testing mechanism made them immune somehow and obviously we find out today sadly that that wasn't the case for the president, for the First Lady and those folks in the White House.\n",
      "Filtered 70000 samples: {'transcript_id': 'CNN-324420', 'matched_terms': {'know': 'ungraded', 'may': 'ungraded', 'seems': 'ungraded'}, 'previous_statement': 'Yes. John, slightly different than times in the past where we are forced out Tiananmen Square. This time, we were politely escorted out of Tiananmen Square. But, as far as Xi Jinping goes, look, this -- Xi Jinping thought being inscribed, enshrined if you will into the Communist Party\\'s Constitution is something that we have not seen. The China is Communist Party dos since the days of Mao Zedong. You have Mao Zedong thought written into the constitution. And now, you have Xi Jinping thought. That puts Xi at a level that we haven\\'t seen since Mao Zedong. Not even Deng Xiaoping, Mao\\'s successor, managed to get to that level. So, really, we can\\'t overstate the importance of this moving forward for Xi. He\\'s managed to amass an incredible amount of political party over -- or power, rather, over the last next five years and it really puts him in a unique position, moving forward over the next five years to really kind of do what he wants to do. He is now the undisputed center of power for not only the Communist Party but for China internally and abroad. It really is quite the accomplishment for Xi Jinping to have his name. Even if it\\'s relatively symbolic, his name, next to the word \"thought\" written into this constitution.', 'statement': \"You <KNOW>, normally, at these party meetings they happen twice a decade, the leader will reveal their heir apparent and, you know, those closest to him. But it <SEEMS> that <MAY> not even happen this time. What's the deal and schedule on all of that?\"}\n",
      "Graded Statement Skipped 314:  Yes, well, Wolf this <MAY> have actually been the reason that Jared Kushner and Ivanka Trump cut their portion of the overseas trip short. The official White House line was the couple always planned to head back home after the Vatican visit, but sources are now telling CNN that Kushner knew the story was about to break and didn't want to be standing with his father-in-law on a foreign trip when it did.\n",
      "Graded Statement Skipped 315:  Well, Wolf, there was some sense that coming off that nine-day foreign trip, they would be able to have -- the White House would be able to have some momentum going forward, dealing with a number of major issues and decisions. But it's very <CLEAR> upon landing that the Russia investigation isn't going away any time soon, even as today there was a moment that underscored in vivid, vivid reality the weight of the office the president now holds.\n",
      "Graded Statement Skipped 316:  Or <MAYBE> there will be military soldiers.\n",
      "Total Skipped Examples: 316\n",
      "Total Processed Examples: 70423\n"
     ]
    }
   ],
   "source": [
    "# Initialize the results list\n",
    "ungraded_data = []\n",
    "i = 0\n",
    "j=0\n",
    "# Filter the data\n",
    "for sample in json_data:\n",
    "    # Check if the statement has been graded already\n",
    "    j+=1\n",
    "    sample_statement = sample['transcript_id'] + \" - \" + sample['previous_statement']\n",
    "    # print(sample_statement)\n",
    "    if sample_statement not in graded_statements:\n",
    "        if sample_statement == \"CNN-412394 - It's important say over and over and over and over and over again on this day, we wish the president well and we wish him a speedy recovery but it is just a fact, it is just a fact that his behavior, the way he has conducted himself in recent days and weeks is directly contrary to the advice of his own experts.\":\n",
    "            print(\"sample_statement mistakenly added:\", sample_statement)\n",
    "        # Only add the sample if there are any filtered terms\n",
    "        ungraded_data.append(sample)\n",
    "        if j%10000==0:\n",
    "            print(f\"Filtered {j} samples: {sample}\")\n",
    "    else:\n",
    "        if sample_statement == \"CNN-412394 - It's important say over and over and over and over and over again on this day, we wish the president well and we wish him a speedy recovery but it is just a fact, it is just a fact that his behavior, the way he has conducted himself in recent days and weeks is directly contrary to the advice of his own experts.\":\n",
    "            print(\"sample_statement correctly skipped added:\", sample_statement)\n",
    "        i +=1\n",
    "        if i > 290:\n",
    "            # if i%10==0:\n",
    "            print(f\"Graded Statement Skipped {i}: \", sample['statement'])\n",
    "\n",
    "print(\"Total Skipped Examples:\", i)\n",
    "print(\"Total Processed Examples:\", j)\n",
    "# Output the filtered results as JSON\n",
    "with open('data/new_filtered_utterances.json', 'w') as output_file:\n",
    "    json.dump(ungraded_data, output_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Created Groups of 100, starting with 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "Saved File: 4\n",
      "Saved File: 5\n",
      "Saved File: 6\n",
      "Saved File: 7\n",
      "Saved File: 8\n",
      "Saved File: 9\n",
      "Saved File: 10\n",
      "Saved File: 11\n",
      "Saved File: 12\n",
      "Saved File: 13\n",
      "Saved File: 14\n",
      "Saved File: 15\n",
      "Saved File: 16\n",
      "Saved File: 17\n",
      "Saved File: 18\n",
      "Saved File: 19\n",
      "Saved File: 20\n",
      "Data split into 20 files with up to 100 samples each.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import json\n",
    "\n",
    "last_completed_file = 3\n",
    "\n",
    "# Number of samples per file\n",
    "random.shuffle(ungraded_data)\n",
    "\n",
    "samples_per_file = 100\n",
    "total_samples = len(ungraded_data)\n",
    "total_files = math.ceil(total_samples / samples_per_file)\n",
    "\n",
    "r = 20 - last_completed_file\n",
    "print(r)\n",
    "# Generate a list of indices in random order\n",
    "indices = list(range(r))\n",
    "\n",
    "# Split data into chunks and save to separate files using shuffled indices\n",
    "for i in indices:\n",
    "    start_index = i * samples_per_file\n",
    "    end_index = start_index + samples_per_file\n",
    "    chunk = ungraded_data[start_index:end_index]\n",
    "    \n",
    "    # Generate filename based on the chunk number\n",
    "    filename = f'data/new_filtered_utterances_to_grade/filtered_data_HN_part_{i + last_completed_file + 1}.json'\n",
    "    \n",
    "    # Save the chunk to a file\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(chunk, file, indent=2)\n",
    "    filename = f'data/new_filtered_utterances_to_grade/filtered_data_MW_part_{i + last_completed_file + 1}.json'\n",
    "    print(\"Saved File:\", i+last_completed_file+1)\n",
    "    # Save the chunk to a file\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(chunk, file, indent=2)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Data split into {20} files with up to {samples_per_file} samples each.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "know: none percentage: 51.61% \n",
      " * h/a_count: 30\n",
      " * none_count: 32\n",
      "\n",
      "about: none percentage: 91.18% \n",
      " * h/a_count: 3\n",
      " * none_count: 31\n",
      "\n",
      "well: none percentage: 89.66% \n",
      " * h/a_count: 3\n",
      " * none_count: 26\n",
      "\n",
      "could: none percentage: 57.14% \n",
      " * h/a_count: 12\n",
      " * none_count: 16\n",
      "\n",
      "think: none percentage: 22.92% \n",
      " * h/a_count: 37\n",
      " * none_count: 11\n",
      "\n",
      "around: none percentage: 83.33% \n",
      " * h/a_count: 2\n",
      " * none_count: 10\n",
      "\n",
      "thought: none percentage: 80.00% \n",
      " * h/a_count: 2\n",
      " * none_count: 8\n",
      "\n",
      "believe: none percentage: 53.85% \n",
      " * h/a_count: 6\n",
      " * none_count: 7\n",
      "\n",
      "should: none percentage: 35.29% \n",
      " * h/a_count: 11\n",
      " * none_count: 6\n",
      "\n",
      "feel: none percentage: 83.33% \n",
      " * h/a_count: 1\n",
      " * none_count: 5\n",
      "\n",
      "best: none percentage: 100.00% \n",
      " * h/a_count: 0\n",
      " * none_count: 5\n",
      "\n",
      "sure: none percentage: 44.44% \n",
      " * h/a_count: 5\n",
      " * none_count: 4\n",
      "\n",
      "may: none percentage: 20.00% \n",
      " * h/a_count: 16\n",
      " * none_count: 4\n",
      "\n",
      "thinking: none percentage: 100.00% \n",
      " * h/a_count: 0\n",
      " * none_count: 4\n",
      "\n",
      "hope: none percentage: 100.00% \n",
      " * h/a_count: 0\n",
      " * none_count: 4\n",
      "\n",
      "kind of: none percentage: 30.00% \n",
      " * h/a_count: 7\n",
      " * none_count: 3\n",
      "\n",
      "doubt: none percentage: 75.00% \n",
      " * h/a_count: 1\n",
      " * none_count: 3\n",
      "\n",
      "hoping: none percentage: 100.00% \n",
      " * h/a_count: 0\n",
      " * none_count: 2\n",
      "\n",
      "fact: none percentage: 8.33% \n",
      " * h/a_count: 11\n",
      " * none_count: 1\n",
      "\n",
      "probably: none percentage: 14.29% \n",
      " * h/a_count: 6\n",
      " * none_count: 1\n",
      "\n",
      "quite: none percentage: 33.33% \n",
      " * h/a_count: 2\n",
      " * none_count: 1\n",
      "\n",
      "guessing: none percentage: 100.00% \n",
      " * h/a_count: 0\n",
      " * none_count: 1\n",
      "\n",
      "might: none percentage: 14.29% \n",
      " * h/a_count: 6\n",
      " * none_count: 1\n",
      "\n",
      "knows: none percentage: 100.00% \n",
      " * h/a_count: 0\n",
      " * none_count: 1\n",
      "\n",
      "clear: none percentage: 25.00% \n",
      " * h/a_count: 3\n",
      " * none_count: 1\n",
      "\n",
      "view: none percentage: 50.00% \n",
      " * h/a_count: 1\n",
      " * none_count: 1\n",
      "\n",
      "opinion: none percentage: 100.00% \n",
      " * h/a_count: 0\n",
      " * none_count: 1\n",
      "\n",
      "suspect: none percentage: 100.00% \n",
      " * h/a_count: 0\n",
      " * none_count: 1\n",
      "\n",
      "doubts: none percentage: 100.00% \n",
      " * h/a_count: 0\n",
      " * none_count: 1\n",
      "\n",
      "totally: none percentage: 33.33% \n",
      " * h/a_count: 2\n",
      " * none_count: 1\n",
      "\n",
      "guess: none percentage: 50.00% \n",
      " * h/a_count: 1\n",
      " * none_count: 1\n",
      "\n",
      "suspects: none percentage: 100.00% \n",
      " * h/a_count: 0\n",
      " * none_count: 1\n",
      "\n",
      "of course: none percentage: 33.33% \n",
      " * h/a_count: 2\n",
      " * none_count: 1\n",
      "\n",
      "thinks: none percentage: 50.00% \n",
      " * h/a_count: 1\n",
      " * none_count: 1\n",
      "\n",
      "believes: none percentage: 100.00% \n",
      " * h/a_count: 0\n",
      " * none_count: 1\n",
      "\n",
      "definitely: none percentage: 0.00% \n",
      " * h/a_count: 5\n",
      " * none_count: 0\n",
      "\n",
      "seems: none percentage: 0.00% \n",
      " * h/a_count: 5\n",
      " * none_count: 0\n",
      "\n",
      "maybe: none percentage: 0.00% \n",
      " * h/a_count: 12\n",
      " * none_count: 0\n",
      "\n",
      "stuff: none percentage: 0.00% \n",
      " * h/a_count: 5\n",
      " * none_count: 0\n",
      "\n",
      "sort of: none percentage: 0.00% \n",
      " * h/a_count: 11\n",
      " * none_count: 0\n",
      "\n",
      "appear: none percentage: 0.00% \n",
      " * h/a_count: 2\n",
      " * none_count: 0\n",
      "\n",
      "confident: none percentage: 0.00% \n",
      " * h/a_count: 2\n",
      " * none_count: 0\n",
      "\n",
      "absolutely: none percentage: 0.00% \n",
      " * h/a_count: 3\n",
      " * none_count: 0\n",
      "\n",
      "suppose: none percentage: 0.00% \n",
      " * h/a_count: 1\n",
      " * none_count: 0\n",
      "\n",
      "perhaps: none percentage: 0.00% \n",
      " * h/a_count: 4\n",
      " * none_count: 0\n",
      "\n",
      "possibly: none percentage: 0.00% \n",
      " * h/a_count: 1\n",
      " * none_count: 0\n",
      "\n",
      "reportedly: none percentage: 0.00% \n",
      " * h/a_count: 1\n",
      " * none_count: 0\n",
      "\n",
      "somewhat: none percentage: 0.00% \n",
      " * h/a_count: 1\n",
      " * none_count: 0\n",
      "\n",
      "knowing: none percentage: 0.00% \n",
      " * h/a_count: 1\n",
      " * none_count: 0\n",
      "\n",
      "obviously: none percentage: 0.00% \n",
      " * h/a_count: 4\n",
      " * none_count: 0\n",
      "\n",
      "approximately: none percentage: 0.00% \n",
      " * h/a_count: 1\n",
      " * none_count: 0\n",
      "\n",
      "apparently: none percentage: 0.00% \n",
      " * h/a_count: 2\n",
      " * none_count: 0\n",
      "\n",
      "appears: none percentage: 0.00% \n",
      " * h/a_count: 1\n",
      " * none_count: 0\n",
      "\n",
      "certainly: none percentage: 0.00% \n",
      " * h/a_count: 3\n",
      " * none_count: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Sample JSON data\n",
    "# with open('data/new_filtered_utterances_to_grade/filtered_data_MW_part_2.json', 'r') as prev_grade:\n",
    "#     prev_grade2 = json.load(prev_grade)\n",
    "with open('data/new_filtered_utterances_to_grade/filtered_data_MW_part_3.json', 'r') as prev_grade:\n",
    "    prev_grade3 = json.load(prev_grade)\n",
    "with open('data/new_filtered_utterances_to_grade/filtered_data_MW_part_4.json', 'r') as prev_grade:\n",
    "    prev_grade4 = prev_grade3+json.load(prev_grade)\n",
    "\n",
    "# Dictionary to store the count of each term for each category\n",
    "term_count = {}\n",
    "\n",
    "# Iterate through each item in the data\n",
    "for item in prev_grade4:\n",
    "    matched_terms = item['matched_terms']\n",
    "    for term, category in matched_terms.items():\n",
    "        # Initialize the term dictionary if not already present\n",
    "        if term not in term_count:\n",
    "            term_count[term] = {}\n",
    "        # Initialize the category count if not already present\n",
    "        if category not in term_count[term]:\n",
    "            term_count[term][category] = 0\n",
    "        # Increment the count for this category under the term\n",
    "        term_count[term][category] += 1\n",
    "\n",
    "\n",
    "sorted_term_count = dict(sorted(term_count.items(), key=lambda item: item[1].get('none', 0), reverse=True))\n",
    "\n",
    "# Output the term count dictionary\n",
    "# print(json.dumps(term_count, indent=2))\n",
    "for item in sorted_term_count:\n",
    "    # print(item, term_count[item])\n",
    "    values = term_count[item]\n",
    "    sample_count = 0\n",
    "    none_count = 0\n",
    "    for k, v in values.items():\n",
    "        sample_count+=v\n",
    "        if k == \"none\":\n",
    "            none_count += v\n",
    "    print(f\"{item}: none percentage: {none_count/sample_count*100:.2f}% \\n * h/a_count: {sample_count-none_count}\\n * none_count: {none_count}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: none, Count: 198\n",
      "Category: hedge, Count: 163\n",
      "Category: authority, Count: 73\n",
      "Total: 434, None Rate: 45.62%\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store the count of each category across all terms\n",
    "category_count = {}\n",
    "\n",
    "# Iterate through each item in the data\n",
    "for item in prev_grade4:\n",
    "    matched_terms = item['matched_terms']\n",
    "    for term, category in matched_terms.items():\n",
    "        # Initialize the category count if not already present\n",
    "        if category not in category_count:\n",
    "            category_count[category] = 0\n",
    "        # Increment the count for this category\n",
    "        category_count[category] += 1\n",
    "\n",
    "# Sort the categories based on their count, descending\n",
    "sorted_category_count = dict(sorted(category_count.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Output the sorted category count\n",
    "for category, count in sorted_category_count.items():\n",
    "    if category == \"hedge\":\n",
    "        hedge = count\n",
    "    if category == \"authority\":\n",
    "        auth = count\n",
    "    if category == \"none\":\n",
    "        none = count\n",
    "    print(f\"Category: {category}, Count: {count}\")\n",
    "print(f\"Total: {hedge+auth+none}, None Rate: {none/(hedge+auth+none)*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
