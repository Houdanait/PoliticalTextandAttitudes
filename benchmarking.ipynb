{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from prompts import system_prompt\n",
    "\n",
    "system_prompt = \"\"\"You are a linguist analyzing dialogue transcripts for examples of \"hedging\" or \"authority\" pragmatic markers. You are given a transcript with the terms highlighted in brackets and capitalized. Provide an answer for every single term in the list of \"terms\" you are given. Return your answer in the following JSON format:\n",
    "\n",
    "---BEGIN SAMPLE INPUT---\n",
    "terms: [\"believe\", \"maybe\", \"certainly\", \"best\"]\n",
    "transcript:\n",
    "Speaker 1: \"In the run for the presidency.\"\n",
    "Speaker 2: \"I knew about one incident. Understand the whole time that he ran for office, I knew that he had had one liaison. It still -- it still tore me up, I mean, personally tore me up. Did I think that one liaison would disqualify him to be the president? You know, we've had great presidents who I would hope one liaison would not have -- have stopped from serving us. That's what I believed. And I believed that until, golly, <MAYBE> long after it made any sense to but, <CERTAINLY> long after -- I mean, long after he was out of the race. And so sometimes I had to, you know, bite my tongue. I talked a lot about his policies, which I still <BELIEVE> were the <BEST> policies and set the standard for the other candidates on a lot of issues -- health care being one of them, but environment and poverty and corporate interference with government. And I really believed that that I could talk about those things and mean every word that I was saying, and have him as an advocate for those issues and meaning that as well.\"\n",
    "---END SAMPLE INPUT---\n",
    "\n",
    "---BEGIN SAMPLE RESPONSE---\n",
    "    {{\n",
    "        \"believe\": \"hedge\",\n",
    "        \"maybe\": \"hedge\",\n",
    "        \"certainly\": \"authority\",\n",
    "        \"best\": \"none\"\n",
    "    }}\n",
    "---END SAMPLE RESPONSE---\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from pyauth import openaikey\n",
    "\n",
    "client = OpenAI(api_key=openaikey)\n",
    "\n",
    "sample_text = {\n",
    "        \"transcript_id\": \"CNN-235715\",\n",
    "        \"statement_id\": \"640bf44d-6500-4a11-a473-4195d48baf31\",\n",
    "        \"matched_terms\": {\n",
    "            \"about\": \"none\",\n",
    "            \"know\": \"none\"\n",
    "        },\n",
    "        \"previous_statement\": \"Actually this is\",\n",
    "        \"statement\": \"The Vines that you've posted show some incredible sights and sounds, rockets, shaking buildings, ambulances in the night. What do you want people to <KNOW> <ABOUT> life inside Gaza?\"\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(json_response, verbose=False):\n",
    "    matched_terms_list = []\n",
    "    for matched_term in json_response[\"matched_terms\"]:\n",
    "        matched_terms_list.append(matched_term)\n",
    "\n",
    "    string = f\"\"\"terms: {matched_terms_list}\"\\nTranscript:\\nSpeaker 1: \"{json_response[\"previous_statement\"]}\"\\nSpeaker 2: \"{json_response[\"statement\"]}\" \"\"\"\n",
    "    \n",
    "    transcript_id = json_response[\"transcript_id\"]\n",
    "    statement_id = json_response[\"statement_id\"]\n",
    "    if verbose:\n",
    "        print(\"Parsing\", statement_id)\n",
    "    previous_statement = json_response[\"previous_statement\"]\n",
    "    statement = json_response[\"statement\"]\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Parsed JSON:\", transcript_id, statement_id, matched_terms_list, previous_statement, statement)\n",
    "\n",
    "    return transcript_id, statement_id, json_response[\"matched_terms\"], matched_terms_list, previous_statement, statement, matched_terms_list, string\n",
    "\n",
    "\n",
    "def get_json_response(string, model=\"gpt-3.5-turbo\", system_prompt=system_prompt, verbose=False):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": string}\n",
    "        ]\n",
    "    )\n",
    "    completion = response.choices[0].message.content\n",
    "    parsed_response = json.loads(completion)\n",
    "    if verbose:\n",
    "        print(\"Received response from model.\")\n",
    "\n",
    "    return parsed_response\n",
    "\n",
    "def update_grade_json_gpt(json_example, model = \"gpt-3.5-turbo\", verbose=False):\n",
    "    transcript_id, statement_id, matched_terms, matched_terms_list, previous_statement, statement, matched_terms_list, string = parse_json(json_example)\n",
    "    parsed_response = get_json_response(string)\n",
    "    output_matched_items = {}\n",
    "    # print(\"Matched Terms:\",matched_terms_list)\n",
    "    for item in matched_terms_list:\n",
    "        if verbose:\n",
    "            print(\"Matching item:\", item)\n",
    "            print(\"   Correct Response:\", matched_terms[item])\n",
    "            print(\"   Model Response:\", parsed_response[item])\n",
    "        item_vals = {\n",
    "            \"correct\": matched_terms[item],\n",
    "            model : parsed_response[item]\n",
    "        }\n",
    "        output_matched_items[item] = item_vals\n",
    "\n",
    "    benchmark_output = {\n",
    "        \"transcript_id\": transcript_id,\n",
    "        \"statement_id\": statement_id,\n",
    "        \"matched_terms\": output_matched_items,\n",
    "        \"previous_statement\": previous_statement,\n",
    "        \"statement\": statement\n",
    "    }\n",
    "    if verbose:\n",
    "        print(\"Completed grading:\", benchmark_output)    \n",
    "    return benchmark_output\n",
    "\n",
    "def insert_new_row_json(json_example, model = \"gpt-3.5-turbo\", verbose=False):\n",
    "    transcript_id, statement_id, matched_terms, matched_terms_list, previous_statement, statement, matched_terms_list, string = parse_json(json_example)\n",
    "    parsed_response = get_json_response(string)\n",
    "    output_matched_items = {}\n",
    "    # print(\"Matched Terms:\",matched_terms_list)\n",
    "    for item in matched_terms_list:\n",
    "        if verbose:\n",
    "            print(\"Matching item:\", item)\n",
    "            print(\"   Correct Response:\", matched_terms[item])\n",
    "            print(\"   Model Response:\", parsed_response[item])\n",
    "        item_vals = {\n",
    "            \"correct\": matched_terms[item],\n",
    "            model : parsed_response[item]\n",
    "        }\n",
    "        output_matched_items[item] = item_vals\n",
    "\n",
    "    benchmark_output = {\n",
    "        \"transcript_id\": transcript_id,\n",
    "        \"statement_id\": statement_id,\n",
    "        \"matched_terms\": output_matched_items,\n",
    "        \"previous_statement\": previous_statement,\n",
    "        \"statement\": statement\n",
    "    }\n",
    "    if verbose:\n",
    "        print(\"Completed grading:\", benchmark_output)    \n",
    "    return benchmark_output\n",
    "\n",
    "\n",
    "# x = update_grade_json_gpt(text)\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get GPT3.5 Responses\n",
    "\n",
    "Update code to also incorporate 4, gemini, etc. Need to have the code update if something already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 249 examples from data/human_annotated_model_response.json\n",
      "Processed and saved 10 samples\n",
      "Processed and saved 20 samples\n",
      "Processed and saved 30 samples\n",
      "Processed and saved 40 samples\n",
      "Processed and saved 50 samples\n",
      "Processed and saved 60 samples\n",
      "Processed and saved 70 samples\n",
      "Processed and saved 80 samples\n",
      "Processed and saved 90 samples\n",
      "Processed and saved 100 samples\n",
      "Processed and saved 110 samples\n",
      "Processed and saved 120 samples\n",
      "Processed and saved 130 samples\n",
      "Processed and saved 140 samples\n",
      "Processed and saved 150 samples\n",
      "Processed and saved 160 samples\n",
      "Processed and saved 170 samples\n",
      "Processed and saved 180 samples\n",
      "Processed and saved 190 samples\n",
      "Processed and saved 200 samples\n",
      "Processed and saved 210 samples\n",
      "Processed and saved 220 samples\n",
      "Processed and saved 230 samples\n",
      "Processed and saved 240 samples\n",
      "\n",
      "Model Tally:\n",
      " correct: 249\n",
      " gpt-3.5-turbo: 249\n",
      " gpt-4o: 249\n",
      " gpt-4-turbo: 249\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data from a file\n",
    "file_path = 'data/human_annotated_model_response.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    ground_truth = json.load(file)\n",
    "\n",
    "print(\"Loaded\", len(ground_truth), \"examples from\", file_path)\n",
    "\n",
    "# output_dict = {f\"{{sample['statement_id']}\": sample for sample in ground_truth}\n",
    "output_dict = {f\"{sample['transcript_id']}_{sample['statement_id']}\": sample for sample in ground_truth}\n",
    "\n",
    "models_list = [\"correct\", \"gpt-3.5-turbo\", \"gpt-4o\", \"gpt-4-turbo\"]\n",
    "tally = {model: 0 for model in models_list}\n",
    "i = 0\n",
    "for sample in ground_truth:  # Adjust this to process more samples if needed\n",
    "    transcript_id, statement_id, matched_terms, matched_terms_list, previous_statement, statement, matched_terms_list, string = parse_json(sample)\n",
    "    \n",
    "    # print(\"Matched_terms\", matched_terms)\n",
    "\n",
    "    # Iterate through only the first matched term\n",
    "    first_term, models = next(iter(matched_terms.items()))\n",
    "    \n",
    "    # Iterate through each model name and its matched value\n",
    "    for model_name in models_list:\n",
    "        if model_name in models:\n",
    "            # print(\"Skipping model\", model_name)\n",
    "            tally[model_name] += 1\n",
    "        else:\n",
    "            response = get_json_response(string, model=model_name)\n",
    "            for item in matched_terms:\n",
    "                matched_terms[item][model_name] = response[item]\n",
    "            tally[model_name] += 1\n",
    "    sample_output = {\n",
    "        \"transcript_id\": transcript_id,\n",
    "        \"statement_id\": statement_id,\n",
    "        \"matched_terms\": matched_terms,\n",
    "        \"previous_statement\": previous_statement,\n",
    "        \"statement\": statement\n",
    "    }\n",
    "    output_dict[f\"{transcript_id}_{statement_id}\"] = sample_output\n",
    "    i+=1\n",
    "    if i % 10 == 0:\n",
    "        output = list(output_dict.values())\n",
    "\n",
    "        with open(file_path, 'w') as file:\n",
    "            json.dump(output, file, indent=4, ensure_ascii=False)\n",
    "        print(f\"Processed and saved {i} samples\")\n",
    "\n",
    "output = list(output_dict.values())\n",
    "\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(output, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Print the tally\n",
    "print(\"\\nModel Tally:\")\n",
    "for model, count in tally.items():\n",
    "    print(f\" {model}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open(file_path, 'w') as file:\n",
    "#     json.dump(model_responses, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Results for Model: gpt-3.5-turbo\n",
      " * Class: none\n",
      "   Precision: 0.5345\n",
      "   Recall: 0.9029\n",
      "   F1 Score: 0.6715\n",
      "   Accuracy: 0.5054\n",
      "\n",
      " * Class: hedge\n",
      "   Precision: 0.6540\n",
      "   Recall: 0.6603\n",
      "   F1 Score: 0.6571\n",
      "   Accuracy: 0.4894\n",
      "\n",
      " * Class: authority\n",
      "   Precision: 0.8571\n",
      "   Recall: 0.2176\n",
      "   F1 Score: 0.3471\n",
      "   Accuracy: 0.2100\n",
      "\n",
      "Overall Model Performance:\n",
      "Average Precision: 0.6819\n",
      "Average Recall: 0.5936\n",
      "Average F1 Score: 0.5586\n",
      "Average Accuracy: 0.4016\n",
      "Total Accuracy: 0.6020\n",
      "\n",
      "\n",
      "Results for Model: gpt-4-turbo\n",
      " * Class: none\n",
      "   Precision: 0.7787\n",
      "   Recall: 0.9377\n",
      "   F1 Score: 0.8509\n",
      "   Accuracy: 0.7404\n",
      "\n",
      " * Class: hedge\n",
      "   Precision: 0.9242\n",
      "   Recall: 0.7358\n",
      "   F1 Score: 0.8193\n",
      "   Accuracy: 0.6940\n",
      "\n",
      " * Class: authority\n",
      "   Precision: 0.7143\n",
      "   Recall: 0.6481\n",
      "   F1 Score: 0.6796\n",
      "   Accuracy: 0.5147\n",
      "\n",
      "Overall Model Performance:\n",
      "Average Precision: 0.8057\n",
      "Average Recall: 0.7739\n",
      "Average F1 Score: 0.7833\n",
      "Average Accuracy: 0.6497\n",
      "Total Accuracy: 0.8240\n",
      "\n",
      "\n",
      "Results for Model: gpt-4o\n",
      " * Class: none\n",
      "   Precision: 0.6178\n",
      "   Recall: 0.9817\n",
      "   F1 Score: 0.7584\n",
      "   Accuracy: 0.6108\n",
      "\n",
      " * Class: hedge\n",
      "   Precision: 0.9336\n",
      "   Recall: 0.6589\n",
      "   F1 Score: 0.7725\n",
      "   Accuracy: 0.6294\n",
      "\n",
      " * Class: authority\n",
      "   Precision: 0.7959\n",
      "   Recall: 0.4333\n",
      "   F1 Score: 0.5612\n",
      "   Accuracy: 0.3900\n",
      "\n",
      "Overall Model Performance:\n",
      "Average Precision: 0.7825\n",
      "Average Recall: 0.6913\n",
      "Average F1 Score: 0.6974\n",
      "Average Accuracy: 0.5434\n",
      "Total Accuracy: 0.7418\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data from a file\n",
    "file_path = 'data/human_annotated_model_response.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    data_list = json.load(file)\n",
    "\n",
    "# Initialize a dictionary to hold the confusion matrix\n",
    "\n",
    "model_list = ['gpt-3.5-turbo', 'gpt-4-turbo', \"gpt-4o\"]\n",
    "\n",
    "for model in model_list:\n",
    "    # Populate confusion matrix from the JSON data\n",
    "    confusion_matrix = {}\n",
    "    for entry in data_list:\n",
    "        matched_terms = entry[\"matched_terms\"]\n",
    "        for term, details in matched_terms.items():\n",
    "            correct_answer = details[\"correct\"]\n",
    "            model_answer = details[model]\n",
    "\n",
    "            if correct_answer not in confusion_matrix:\n",
    "                confusion_matrix[correct_answer] = {}\n",
    "\n",
    "            if model_answer not in confusion_matrix[correct_answer]:\n",
    "                confusion_matrix[correct_answer][model_answer] = 0\n",
    "\n",
    "            confusion_matrix[correct_answer][model_answer] += 1\n",
    "\n",
    "    # Calculate precision, recall, F1, and accuracy for each class\n",
    "\n",
    "    print(\"\\n\\nResults for Model:\", model)\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "    accuracies = []\n",
    "\n",
    "    total_correct = 0\n",
    "    total_instances = 0\n",
    "\n",
    "    for correct_class, predictions in confusion_matrix.items():\n",
    "        true_positive = predictions.get(correct_class, 0)\n",
    "        false_positive = sum(predictions.get(pred, 0) for pred in predictions if pred != correct_class)\n",
    "        false_negative = sum(confusion_matrix.get(pred, {}).get(correct_class, 0) for pred in confusion_matrix if pred != correct_class)\n",
    "        true_negative = total_instances - (true_positive + false_positive + false_negative)  # Not used directly\n",
    "\n",
    "        precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "        recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        accuracy = true_positive / (true_positive + false_positive + false_negative) if (true_positive + false_positive + false_negative) > 0 else 0\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        total_correct += true_positive\n",
    "        total_instances += sum(predictions.values())\n",
    "\n",
    "        print(f\" * Class: {correct_class}\")\n",
    "        print(f\"   Precision: {precision:.4f}\")\n",
    "        print(f\"   Recall: {recall:.4f}\")\n",
    "        print(f\"   F1 Score: {f1:.4f}\")\n",
    "        print(f\"   Accuracy: {accuracy:.4f}\")\n",
    "        print()\n",
    "\n",
    "    print(\"Overall Model Performance:\")\n",
    "    print(f\"Average Precision: {sum(precisions) / len(precisions):.4f}\")\n",
    "    print(f\"Average Recall: {sum(recalls) / len(recalls):.4f}\")\n",
    "    print(f\"Average F1 Score: {sum(f1_scores) / len(f1_scores):.4f}\")\n",
    "    print(f\"Average Accuracy: {sum(accuracies) / len(accuracies):.4f}\")\n",
    "    print(f\"Total Accuracy: {total_correct / total_instances:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Found\n",
      "existing_ids: {'00bf56cc-fe9c-4d47-a819-4c9afc2f752e', '02fc136b-ee5e-48ee-9f49-a23393726098', '62d61c24-0dd4-4eee-9b39-5411249b7eed', '163388f2-1595-42d0-b05c-133fdf728565', 'dfd8e585-a87f-4f2a-abb6-bfa9a524faee', '7e3f2290-f887-4c2b-b197-f2ebf2fdb1ca', '982c73d7-30e3-48fe-8190-588e49c92d1c', '81af1662-0e4f-48be-8a6d-43f88d61e057', '96b7405f-271e-4a81-8c32-c8f2002bcfa2', 'b3ce21d5-64b0-4d6a-99f0-6a4220ef242b', 'c6c25597-79ab-4b73-b03a-382b1d458dce', '6fc74628-4118-4440-b1bb-e270006ba947', '4cc981b3-c351-4539-ba7f-fb4d4f5b8e94', '84be6cab-37c1-4322-87cf-3419ad31d53f', 'ba25fea4-9b70-4969-91e5-32daabe0ac11', '627a7126-325b-4299-98d4-ef1d119bf740', '640bf44d-6500-4a11-a473-4195d48baf31', '764918f9-d387-4693-924a-3c0feb09c51e', '1f0054fd-2145-4ace-9b93-4b647ed610b6', '586f558e-edc0-4a87-a4a7-a3e2e5b94206', '70f315e2-8b16-44a4-8d37-9222180ea992', '52ccdd93-9217-4ce4-8a9f-4db59a04fb63', 'be90174f-d9ae-4768-80fa-61e61354b93e', '5887e546-168a-474f-ae38-14e7aead8ce6', '9dd5620e-e89f-453d-a536-eaab2dc4f248', '8ab54e7a-a3f2-4372-80b0-4bb0d5c0d6c1', 'baa8a838-dd99-471d-9445-7be0ef28fe05', 'edd45276-54d8-4e5b-90f1-0ddbcb97174a', 'a4cf4ab4-a480-4036-8983-f2a4d0666435', '10ede676-53e6-4a87-b006-2ef8f380127b', '9629ae9e-d8ee-4f69-9bd7-5a960269f2fa', 'fc25cb84-8ee3-4c58-b8c2-cc72741dfde8', 'dfc30b66-75e1-4a53-bbcb-e1655b4abeb9', 'c8c6604a-f008-4a70-9afb-4b7d6c4d5c7c', 'b7648c0d-5b1a-48f8-8f86-f35e287d9163', '894cf0f8-d0da-4679-89c2-d713294f99bd', '72e39cbf-2460-4bef-8c6b-47f43803ed47', '18bb6f73-a79b-430c-bdff-ea44f1157ae8', '8dea2efb-b963-4dee-97f5-37ebb32a9502', '180799e0-2616-4ff4-b1ce-99e2efa6bd40', '50e85678-8734-4f69-98a7-b2a7222ca654', 'aeab9782-e456-4b0f-ad4f-f974ba1cb51c', 'fa87189b-3699-4f3d-82b8-3ed6dcbd864a', 'acca0e25-55f4-495b-a595-c3712dd747c3', 'c9be53a6-d0dc-4a68-a37e-ab393ec29467', '7ad88c56-f8cb-43c2-bdc4-6b412babeac7', '8bde4427-ac2c-46c2-b043-8884a3c8f6b7', '12480580-eeb8-4bd8-a23d-d3876f296a07', 'aab10678-4925-4cf6-93ce-6aab0493aa1d', '8d2a5f49-f5ed-4740-9757-289efebc42d9', '373e1c78-46c7-4cf5-aaba-1711b5710207', 'dad6a79d-081c-4b25-a7c4-f7c8f6fd3fea', '913d652c-c330-4430-88e2-aad72084ea34', '796371ed-23d8-4d1f-877d-3f7aa79a5c84', '4f003d91-ed1f-4515-94c7-4c3b282a6022', 'bb36daef-7879-4196-9090-f263081b4057', '438be66a-ff7d-4101-a307-ba28e6d74f76', '575db7c6-0f57-4c20-85e6-9b5fd6d4a025', '95c71b4f-313e-42bb-a379-26ea6664a5d9', '5b175607-8715-493b-a820-8c658518a02a', '4133d78c-3f5b-4002-8d0c-ba7f4b097b43', '3890ae75-7234-4dbd-a5a5-e6f2ddfb0373', '30814bcf-d281-409c-a6ba-33e9570c3bc3', '5112cece-b267-4a85-b14e-502ccfe34538', 'fab9c439-4cc3-47f3-bfd5-03b81484ba48', '0c753c8e-82db-4766-bf94-2d6d1343b87a', '6219ad2e-1359-4372-b50a-3a0c4a516360', '40141707-a31f-4a1e-9e99-c4cb506a7189', 'cda4afd8-873d-40e9-b5a5-6eb6d205ec4d', '42912f16-1b14-49c2-81c1-b8641b49fb09', '2ed50d91-cc3b-4302-bcda-72ddde4cdc98', 'b5da615b-13fd-437c-a854-ee1a00bda6b2', '9a31725f-2ac9-4b30-bce6-e84e2fa52a8a', '9048547e-05fd-4367-8ff4-b167f9134dad', '222ee0a5-953b-44ec-8149-c02d64cb909b', 'eca13cd2-afdc-4c3c-ae1e-2812e25592e6', '5c0de1a5-93ea-4170-9a32-05026bc6766b', '5ad29644-37fe-4ff8-a1a3-4dc0087826ae', 'fcca8bcf-e22c-459c-94c4-030430eb4754', '79394b87-13dc-4fbe-abd0-6f539ad74836', '8aef5a20-9aac-4f17-9064-03338137d645', '0365c5ba-bb40-49a1-93f6-78532fb1b8da', '930fa225-7718-493a-9d43-828c540944ee', '5df5a2be-d23c-40c5-aab2-e82eccc487f8', '0d6c949b-27fb-4ed1-9a58-92b4442e6135', '01adde68-2304-4877-9390-0bafe5543bd6', 'bdd9dbbd-9f69-4dfb-bd1c-d80244573104', '768a846e-a5eb-4c64-8736-332b8fca27fd', '6be9746c-e695-44c7-873b-3226b873e59d', 'c9625698-13c3-4652-9a8a-0defd5a30eed', 'b8cfd7ab-d293-4cdb-bff2-d04e5ee41bc3', 'b0b6001c-5866-4d71-8c1b-769d17161f4d', 'a5f88649-8240-4e87-b9f5-de022370bd69', 'ca546771-b578-45f4-bd80-e3ccf585aaf9', '9dddd9de-4b9c-4e6c-af84-18a103bb0693', '98794cba-0599-4abb-8bdf-34c70bad2b1c', '411790ca-69a6-4d70-b284-7d494e06efab', 'b4dfc627-d791-451f-9299-bcdfcb25c61d', '493780d3-c807-41e7-b594-53060ff764c5', 'a7764615-aba9-41d3-84cf-be80cd9acdaf', 'a29834dd-f6ca-49d0-808c-73d508b76fe7', '2c218943-b491-4cdc-ae6e-73655bb63762', '0a376ba1-5d75-41b6-b3e7-b32d34d5f4e8', 'f4bb4ada-1bb8-470f-8de9-20ca75226f0d', 'db5ca0a5-9113-4d9c-9e30-401f2f097f77', 'd07e2cbe-eee7-4a83-a98e-d90e01b8134b', '7d247143-cf4a-4cb1-93d8-50f1082aa764', 'e5cf095c-f9f0-4f87-84f0-4f8b8bdf2806', '5bdf2f2f-679c-4d1c-b476-f715fa5b17d7', 'fabb82b9-0bf4-48c2-8346-8eccc4be71c8', '645b537a-2ec7-42ca-9d30-449746abf767', '767b2789-fd8e-4065-a5e9-5189e96e321b', '574f6994-af69-4064-9ef9-138e829c2034', '1db9fe42-db27-44d4-a0e4-73e13953aaad', 'f71167dc-dbac-4c70-96ef-921ad9501acf', '5b4be1d0-7df7-4480-90b0-d27753de7b5d', '9bb37bc9-9ef1-43d7-a49b-7f859da4d23d', '61b01063-f9bb-430b-a95d-8ac39b4f750c', 'f731090f-a019-4b79-ad83-e915096e53da', 'd0c36a6f-bded-46c3-8140-5c320174626a', 'd28f18df-1371-4c2c-a977-cd03e8cae7bb', '32517d2d-f483-46f7-909b-68bc4473e119', '1c16a4c6-a83a-4aa8-bd1f-f76ba0b82337', '3ac11881-2912-4870-a3eb-49abb235a188', 'ddf371a9-8187-4897-a8bc-64477453b51f', '39b1db35-f064-4a7b-9f06-ea9511cf28f7', 'a2a48445-fbc8-43a5-981c-6624f560db83', '891dd70b-ef69-49f6-9ec0-3666d7b8386b', 'ec77335d-3fcb-4ec4-9cbe-8cd058024f18', '4539dbb9-43e9-4094-942c-d20c71e77182', '3f54c8c1-a866-4df3-ac57-eda595d34571', 'e8a16763-23cf-4b93-86f4-5f6846ed539e', 'a3d27eee-c7e0-4141-856a-b6e8c71b63ec', '09c3bcf6-faa5-470a-9fde-3d2df16b8684', 'dd2a4cf2-d154-454a-bd50-e4d70f3e2ed1', '2fc41a9a-c3d4-4911-882a-8370eb907828', '0f2ef064-259e-43c2-beec-26ebd91f756a', 'a0721b33-d343-40a1-ba3d-0e9dc327e923', '344cd045-81ee-4a93-82a4-08430acfa183', 'dd6ece9a-9201-4245-af27-cb7072ade1d3', 'a5a33833-8635-4f71-9839-7e0dce477a48', 'd4b5beb4-71c3-4f6c-9ad9-d1de2706ecb0', '0066f779-3104-4742-a7ab-71e0030bd141', '18d582f4-5d28-40ec-800f-f6352af7977f', '4988cb3f-f2c5-46b6-8c01-d25d9c74bee0', '3908f8ab-5ffe-4a33-9e63-ea6e59303e32', '17684c40-fbac-463b-b210-e7b37a9ac771', '175dad5d-2730-49a1-9473-742833251cfa', 'bb997a83-a043-4398-a039-02de5664a14e', '95ae6fff-5b63-44bf-bdf9-86f31e012674', '1987956f-1808-412a-8953-24592981fe83', 'cf103778-589a-42eb-9147-31ce554d7ba5', 'fe5acb03-0bf5-453d-bb4c-0a46dd268afe', '86601c7b-f2d2-40b6-97cc-bafeb5a672c5', '2cdae4c1-0f51-46fb-8eac-2d5d3eb6cd2d', '0c2441e6-7919-4925-af0d-019ff8d23699', 'ca7254fd-be9f-48ca-9b5d-53b34d823225', 'b3ca5861-d3a8-4af7-b18a-c2154ef2b21b', '9acc8682-2f5f-49b1-919b-560346064ff3', '869efc80-3463-4738-941b-cd06c35a85d5', 'f2c58d1a-1a75-4df8-b2a6-804db2a2dd62', '24cd7138-0ba0-40f5-93ac-65b9f2107b86', '375942fb-ac52-4c16-bdce-aacc6c7a5502', 'd28660db-197c-4432-8311-b1df9e564097', 'b57ba1fa-f69f-4440-8415-598c940075c1', '4aa158b8-31d6-4522-a7de-b46be95c8257', '6de15334-654c-452a-85b2-13988bebff49', 'f7fdbb95-9c34-4199-bc65-a641e44409c3', 'f9970336-3730-4b1a-8c1b-64dce48a7725', '3d68f8cf-072a-4196-b802-b9eda4136939', '7088367d-f9ad-4e0a-ba24-382da32e31ca', '5b2926ef-2336-4cd4-8cc2-29c7457befb8', 'eba956ae-89ba-4e32-a852-c0ad91068640', 'c39d4db2-9b08-4c8c-89e2-ece470e4e050', 'e47115ea-964d-4aa2-bf77-5914730396f2', 'da29817d-1215-4897-baa9-4cd6a0c8238e', '916c806b-ca6b-496a-b70e-ca0764c5e130', 'f1559ac3-b1ff-4cae-8654-833ef2a20d48', '826b0c8f-97da-46df-8b30-cd4d8a5bbcce', '69c5bbae-7041-49d8-b1c9-d37e30338d97', '63e9adf6-b051-45bf-9956-762eb366b026', '5f3f1806-1c72-4d75-8b56-332403dd200a', 'd0f92837-e7c5-46c7-8d49-11c2e0d6a33d', '91799744-5135-43cd-a91d-b045a3e4dd4a', 'b3687fc2-efb8-44dc-bf48-7fbc52a6e0e7', '857b03bd-4ae3-400d-93e7-7b957aab206c', '8a2a06ea-d333-485f-9c9d-665b4df16e85', 'ab0c3199-2078-497a-81af-cfb6642a1ac3', '774c2090-990c-438b-84aa-af78524efd64', '060e5656-7a0d-4e91-8bc9-3dca52da5300', '0f2477e6-89ec-431d-bf61-575d4fe138eb', 'd5414021-8799-4c99-a75a-81f92f525e17', 'e12a89e3-d17e-417e-8df3-83411f62071a', '0ed1c57c-cf39-4df3-b028-e13540b00fb6', 'e8014177-9469-4cd7-abe5-feb3c7c32f55', 'ec1fab27-81b3-40be-a4a1-34a750cede50', '13491e34-bffd-4d4b-b52b-40a47692fac8', '9c21165b-1543-454a-8982-feb28c0b9fa0', '62e853dd-67a4-4626-b83e-8a7beccfb43d', '3d33bdaa-c9cf-405c-b3c7-14453efd104f', '6125773f-5962-4a84-9c38-7d21b4ee0cb8', '697e700b-2b53-49cd-ac83-5af7f7f1fa71', '9f6d3c70-2a4b-4008-a92c-ce8bb1214c25', '37795e8c-0590-42bc-950c-1f905256a86d', '37d30d28-34d4-44e1-905d-73d75db808ef', 'acfeefda-56ee-435c-a05a-57f159645de6', '741f7729-5f0f-4a4e-ae08-2fc6ffb6211e', 'fbbf8158-0d0f-4396-83f5-c9db8ffdcde6', 'bce6ad89-af83-49bc-b27c-77b350830fa9', 'c10dec84-ebc2-4545-bba5-ae2225418e30', '668f1860-f6d6-4dd6-82c6-701be022d55f', '01bf271b-d12f-45aa-941c-3ba8dbd2fae5', 'ae8770a7-6154-449b-a734-753fc8de320d', 'a81bc9b7-3635-4cfc-abc7-6cf9380a1edf', 'd2074584-21d1-46aa-8862-b30744e40f3f', 'a55eb332-9857-4e79-bb07-e9efed36d0eb', '6097ecaa-635f-49b3-87fb-c45f794111ff', 'da888b1e-0aab-4e40-b5b6-d8c8ddb0ca10', '2f1508d5-d909-42ac-b4ed-4c36dd1ca944', '6cc4a47c-f466-46a6-9b46-a9675fc590da', '21552104-481c-40f0-ab5d-b98b1c0c7278', 'd3f87a08-955f-4d4c-9892-35bf4aee9582', '9946b5b5-eaa3-412c-9857-03132ae4c141', 'e3fed1b2-8f21-4867-b218-a3e601bed8b5', 'b670c3c3-7780-4cce-871c-8de1ea432a6a', '4d62d5ca-aca5-4e90-ac72-95193f032cd4', '1febc735-7214-402a-8379-92d956d833f0', '512cd7dc-fc5c-4b1c-a3c9-6542e69d46fc', '7525953b-dfb2-4eb0-a1ac-4de628c6efc3', '87d13506-b69f-449c-a9eb-9c529e34bbde', 'b25e3b0b-34d5-4942-90e9-e27b1f139034', 'b26eb413-ca12-4f8e-a382-906b1a4134a3', 'c0cb4f92-1544-4991-808f-096c7077f784', '12a7b950-f409-4931-94fa-e30c5ac5b9bb', '639637e5-8c20-4918-96b1-877d348f12ef', 'ee275a73-3c23-4669-86c9-ced14916ee02', 'cf0a588d-0dfc-4808-a6ee-746f1ca1ae6f', 'a4fe8e76-67e5-4f38-9e11-2ce6d19121da', '68195371-43e8-4242-a752-b60b22ce4d90', '9bca3a60-cb51-43ae-bd2c-e2adcde6afd9', 'c9a0db93-ed6b-44ce-9ae0-ce1ccb8d6cab', 'b1a80de7-df82-4dcc-9123-f5fd1cbe96fe', '5a52d244-e301-42ca-ada8-c601ef41690a', 'adf8bad1-fb07-4ff3-a239-f8ef1a708090', '3ce29133-80dd-4bef-aa20-c189de832f8f', 'e1b05a91-22b5-42ff-828e-a56ecc4acd11', '7f8bbd84-b242-4ce4-bcd8-a85b3824b7a6', '1f761b3b-2f98-45f8-bda0-57bc3cf0ae2f', '56faf72f-8e10-43d7-b5c6-a568852e69a7'}\n",
      "Statement ID da888b1e-0aab-4e40-b5b6-d8c8ddb0ca10 found in data. Checking for model results\n",
      "Parsing da888b1e-0aab-4e40-b5b6-d8c8ddb0ca10\n",
      "Parsed JSON: NPR-43285 da888b1e-0aab-4e40-b5b6-d8c8ddb0ca10 ['best', 'every', 'know', 'only', 'probably', 'maybe', 'thing'] So you would just add a little as your life happened? I was adding to it, and if it was funny and it was true, I      kept it.  And if it wasn't funny and people didn't respond to it, I      dropped it. And so it was really--you <KNOW>, it was performance art that I      just memorized the <BEST> parts of.  The <ONLY> <THING> I really miss <ABOUT>      doing it these days is that there's <<MAYBE>> a few people in <EVERY> crowd      that haven't heard it, but it's nothing like having the few hundred or a      few thousand people years and years ago--40 years ago--when nobody had      heard it.  Those moments can't be repeated. And not <ONLY> that, there were      people singing this song together who politically had nothing in common      and <<PROBABLY>> wouldn't have talked to each other.  But to see them <ALL>      singing together reminded me of the spirit of what the country was <ALL>      <ABOUT>, and I was thrilled.  And, unfortunately, those days are gone for      me.  Not--that can't be repeated.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m     matched_entry \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m model_responses \u001b[38;5;28;01mif\u001b[39;00m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatement_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m statement_id)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Update the existing entry with the new model results\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     updated_data \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_grade_json_gpt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatched_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     model_responses \u001b[38;5;241m=\u001b[39m [updated_data \u001b[38;5;28;01mif\u001b[39;00m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatement_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m statement_id \u001b[38;5;28;01melse\u001b[39;00m item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m model_responses]\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[63], line 21\u001b[0m, in \u001b[0;36mupdate_grade_json_gpt\u001b[0;34m(json_example, model, verbose)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_grade_json_gpt\u001b[39m(json_example, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 21\u001b[0m     transcript_id, statement_id, matched_terms, previous_statement, statement, matched_terms_list, string \u001b[38;5;241m=\u001b[39m parse_json(json_example, verbose)\n\u001b[1;32m     22\u001b[0m     parsed_response \u001b[38;5;241m=\u001b[39m get_json_response(string, model\u001b[38;5;241m=\u001b[39mmodel, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m     23\u001b[0m     output_matched_items \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 7)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data from a file\n",
    "file_path = 'data/human_annotated_model_response.json'\n",
    "model = \"gpt-4\"  # Example new model\n",
    "\n",
    "# Read the existing data from the file\n",
    "try:\n",
    "    with open(file_path, 'r') as file:\n",
    "        model_responses = json.load(file)  # Load existing data into a Python data structure\n",
    "        print(\"File Found\")\n",
    "except FileNotFoundError:\n",
    "    model_responses = []  # Assuming the file might not exist and the root is a list\n",
    "    print(\"File Created\")\n",
    "\n",
    "existing_ids = {item['statement_id'] for item in model_responses}\n",
    "print(\"existing_ids:\", existing_ids)\n",
    "\n",
    "# Function to update grade JSON using GPT model\n",
    "def update_grade_json_gpt(json_example, model=\"gpt-4\", verbose=True):\n",
    "    transcript_id, statement_id, matched_terms, previous_statement, statement, matched_terms_list, string = parse_json(json_example, verbose)\n",
    "    parsed_response = get_json_response(string, model=model, verbose=verbose)\n",
    "    output_matched_items = {}\n",
    "\n",
    "    for item in matched_terms_list:\n",
    "        if verbose:\n",
    "            print(\"Matching item:\", item)\n",
    "            print(\"   Correct Response:\", matched_terms[item])\n",
    "            print(\"   Model Response:\", parsed_response[item])\n",
    "        item_vals = {\n",
    "            \"correct\": matched_terms[item][\"correct\"],\n",
    "            model: parsed_response[item]\n",
    "        }\n",
    "        output_matched_items[item] = item_vals\n",
    "\n",
    "    # Merge the existing matched_terms with the new model results\n",
    "    for term, values in output_matched_items.items():\n",
    "        if term in matched_terms:\n",
    "            matched_terms[term][model] = values[model]\n",
    "        else:\n",
    "            matched_terms[term] = values\n",
    "\n",
    "    benchmark_output = {\n",
    "        \"transcript_id\": transcript_id,\n",
    "        \"statement_id\": statement_id,\n",
    "        \"matched_terms\": matched_terms,\n",
    "        \"previous_statement\": previous_statement,\n",
    "        \"statement\": statement\n",
    "    }\n",
    "    if verbose:\n",
    "        print(\"Completed grading:\", benchmark_output)\n",
    "    return benchmark_output\n",
    "\n",
    "\n",
    "# Iterate through examples in ground_truth\n",
    "for example in ground_truth[:1]:\n",
    "    statement_id = example['statement_id']\n",
    "\n",
    "    # Check if statement_id is already in the data\n",
    "    if statement_id in existing_ids:\n",
    "        # Find the corresponding entry in model_responses\n",
    "        print(f\"Statement ID {statement_id} found in data. Checking for model results\")\n",
    "        matched_entry = next(item for item in model_responses if item['statement_id'] == statement_id)\n",
    "\n",
    "        # Update the existing entry with the new model results\n",
    "        updated_data = update_grade_json_gpt(matched_entry, model=model)\n",
    "        model_responses = [updated_data if item['statement_id'] == statement_id else item for item in model_responses]\n",
    "    else:\n",
    "        print(f\"Statement ID {statement_id} not in data. Updating\")\n",
    "        new_data = update_grade_json_gpt(example, model=model)\n",
    "        model_responses.append(new_data)\n",
    "        existing_ids.add(statement_id)  # Add new statement_id to the set\n",
    "\n",
    "# Save the updated model responses back to the file\n",
    "with open(file_path, 'w') as outfile:\n",
    "    json.dump(model_responses, outfile, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
